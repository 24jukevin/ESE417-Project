{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Loading the dataset from UCI website\n",
    "df = pd.read_csv('winequality-red.csv', header = 0, delimiter=';')\n",
    "\n",
    "# Splitting data by class\n",
    "df_3 = df[df.quality ==3]\n",
    "df_4 = df[df.quality ==4]\n",
    "df_5 = df[df.quality ==5]\n",
    "df_6 = df[df.quality ==6]\n",
    "df_7 = df[df.quality ==7]\n",
    "df_8 = df[df.quality ==8]\n",
    "\n",
    "def remove_outliers(df):\n",
    "    # Calculates mean and standard deviation of the input df\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "\n",
    "    # creates a new dataframe for rows that are within their corresponding standard deviation\n",
    "    new_df = df[(np.abs(df - mean) <= 3*std).all(axis=1)]\n",
    "\n",
    "    # Return the dataframe with outliers removed\n",
    "    return new_df\n",
    "\n",
    "# Applying the function to each dataframe\n",
    "df_3_new = remove_outliers(df_3)\n",
    "df_4_new = remove_outliers(df_4)\n",
    "df_5_new = remove_outliers(df_5)\n",
    "df_6_new = remove_outliers(df_6)\n",
    "df_7_new = remove_outliers(df_7)\n",
    "df_8_new = remove_outliers(df_8)\n",
    "\n",
    "# Concatenating all new dataframes by row\n",
    "df_new = pd.concat([df_3_new,df_4_new,df_5_new,df_6_new,df_7_new,df_8_new],axis=0)\n",
    "\n",
    "# Prepare the data\n",
    "X = df_new.drop('quality', axis=1)\n",
    "y = df_new['quality']\n",
    "\n",
    "# Spltting the data set 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.304821</td>\n",
       "      <td>0.525475</td>\n",
       "      <td>0.264070</td>\n",
       "      <td>2.388464</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>15.154270</td>\n",
       "      <td>44.151515</td>\n",
       "      <td>0.996711</td>\n",
       "      <td>3.316756</td>\n",
       "      <td>0.641839</td>\n",
       "      <td>10.414153</td>\n",
       "      <td>5.639807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.641415</td>\n",
       "      <td>0.172812</td>\n",
       "      <td>0.190776</td>\n",
       "      <td>0.869068</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>9.323774</td>\n",
       "      <td>30.121700</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.141002</td>\n",
       "      <td>0.129084</td>\n",
       "      <td>1.016209</td>\n",
       "      <td>0.814505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990640</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070750</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>11.075000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.700000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>1.002600</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1452.000000       1452.000000  1452.000000     1452.000000   \n",
       "mean        8.304821          0.525475     0.264070        2.388464   \n",
       "std         1.641415          0.172812     0.190776        0.869068   \n",
       "min         4.900000          0.120000     0.000000        1.200000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.250000        2.200000   \n",
       "75%         9.200000          0.635000     0.420000        2.600000   \n",
       "max        13.700000          1.580000     0.760000        6.700000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1452.000000          1452.000000           1452.000000  1452.000000   \n",
       "mean      0.081448            15.154270             44.151515     0.996711   \n",
       "std       0.020704             9.323774             30.121700     0.001735   \n",
       "min       0.012000             1.000000              6.000000     0.990640   \n",
       "25%       0.070750             7.000000             21.000000     0.995600   \n",
       "50%       0.079000            13.000000             36.000000     0.996700   \n",
       "75%       0.089000            21.000000             59.000000     0.997800   \n",
       "max       0.267000            48.000000            155.000000     1.002600   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1452.000000  1452.000000  1452.000000  1452.000000  \n",
       "mean      3.316756     0.641839    10.414153     5.639807  \n",
       "std       0.141002     0.129084     1.016209     0.814505  \n",
       "min       2.880000     0.330000     8.400000     3.000000  \n",
       "25%       3.220000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.720000    11.075000     6.000000  \n",
       "max       3.780000     1.130000    14.000000     8.000000  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__max_depth': None, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 101, 'feature_selection__n_features_to_select': 8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.50      0.10      0.17        10\n",
      "           5       0.75      0.79      0.77       123\n",
      "           6       0.71      0.76      0.73       116\n",
      "           7       0.68      0.64      0.66        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.72       291\n",
      "   macro avg       0.44      0.38      0.39       291\n",
      "weighted avg       0.70      0.72      0.70       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42,class_weight='balanced'))),\n",
    "    ('classification', RandomForestClassifier(random_state=42,class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Predictor  Importance\n",
      "1       volatile acidity           1\n",
      "6   total sulfur dioxide           1\n",
      "7                density           1\n",
      "9              sulphates           1\n",
      "10               alcohol           1\n",
      "4              chlorides           2\n",
      "2            citric acid           3\n",
      "8                     pH           4\n",
      "5    free sulfur dioxide           5\n",
      "0          fixed acidity           6\n",
      "3         residual sugar           7\n"
     ]
    }
   ],
   "source": [
    "feature_select = RFE(estimator=RandomForestClassifier(random_state=42,bootstrap=False,class_weight='balanced')).fit(X_train,y_train)\n",
    "\n",
    "importances = feature_select.ranking_\n",
    "feature_names = df.drop(['quality'],axis=1).columns\n",
    "\n",
    "# Create a DataFrame to display the feature importances\n",
    "feature_importances = pd.DataFrame({'Predictor': list(feature_names), 'Importance': importances})\n",
    "feature_importances.sort_values(by='Importance', ascending=True, inplace=True)\n",
    "print(feature_importances)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__max_depth': None, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 5, 'classification__n_estimators': 99, 'feature_selection__n_features_to_select': 7}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.75      0.76      0.75       123\n",
      "           6       0.69      0.76      0.72       116\n",
      "           7       0.69      0.67      0.68        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.70       291\n",
      "   macro avg       0.35      0.36      0.36       291\n",
      "weighted avg       0.68      0.70      0.69       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', MinMaxScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42,class_weight='balanced'))),\n",
    "    ('classification', RandomForestClassifier(random_state=42,class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__max_depth': None, 'classification__max_samples': 0.9, 'classification__min_samples_leaf': 2, 'classification__min_samples_split': 4, 'classification__n_estimators': 102, 'feature_selection__n_features_to_select': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.73      0.77      0.75       123\n",
      "           6       0.68      0.70      0.69       116\n",
      "           7       0.68      0.69      0.68        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.69       291\n",
      "   macro avg       0.35      0.36      0.35       291\n",
      "weighted avg       0.66      0.69      0.68       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42,class_weight='balanced'))),\n",
    "    ('classification', RandomForestClassifier(random_state=42,class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "    'classification__max_samples': [None,0.5,0.7,0.9,1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__max_depth': None, 'classification__max_samples': 0.9, 'classification__min_samples_leaf': 2, 'classification__min_samples_split': 4, 'classification__n_estimators': 102, 'feature_selection__n_features_to_select': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.73      0.77      0.75       123\n",
      "           6       0.68      0.70      0.69       116\n",
      "           7       0.68      0.69      0.68        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.69       291\n",
      "   macro avg       0.35      0.36      0.35       291\n",
      "weighted avg       0.66      0.69      0.68       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42,class_weight='balanced'))),\n",
    "    ('classification', RandomForestClassifier(random_state=42,class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "    'classification__max_samples': [None,0.9,1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': None, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 101, 'feature_selection__estimator__class_weight': 'balanced', 'feature_selection__n_features_to_select': 8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.50      0.10      0.17        10\n",
      "           5       0.75      0.79      0.77       123\n",
      "           6       0.71      0.76      0.73       116\n",
      "           7       0.68      0.64      0.66        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.72       291\n",
      "   macro avg       0.44      0.38      0.39       291\n",
      "weighted avg       0.70      0.72      0.70       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__class_weight': ['balanced'],\n",
    "    'classification__class_weight': ['balanced'],\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6,7,8],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 2.6, 6: 2.761658031088083, 7: 8.785714285714286, 4: 33.3125, 8: 88.83333333333333, 3: 159.9}\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each class\n",
    "class_counts = df_new['quality'].value_counts()\n",
    "\n",
    "# Calculate weights\n",
    "class_weights = {cls: len(df) / count for cls, count in class_counts.items()}\n",
    "\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': {5: 2.6, 6: 2.761658031088083, 7: 8.785714285714286, 4: 33.3125, 8: 88.83333333333333, 3: 159.9}, 'classification__max_depth': None, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 98, 'feature_selection__estimator__class_weight': 'balanced', 'feature_selection__n_features_to_select': 8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.50      0.10      0.17        10\n",
      "           5       0.74      0.80      0.77       123\n",
      "           6       0.70      0.73      0.71       116\n",
      "           7       0.72      0.64      0.68        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71       291\n",
      "   macro avg       0.44      0.38      0.39       291\n",
      "weighted avg       0.70      0.71      0.70       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__class_weight': ['balanced',class_weights],\n",
    "    'classification__class_weight': ['balanced',class_weights],\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6,7,8],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': None, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 102, 'feature_selection__estimator__class_weight': {5: 2.6, 6: 2.761658031088083, 7: 8.785714285714286, 4: 33.3125, 8: 177.66666666666666, 3: 319.8}, 'feature_selection__n_features_to_select': 8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.50      0.10      0.17        10\n",
      "           5       0.75      0.79      0.77       123\n",
      "           6       0.70      0.76      0.73       116\n",
      "           7       0.72      0.64      0.68        36\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.72       291\n",
      "   macro avg       0.44      0.38      0.39       291\n",
      "weighted avg       0.70      0.72      0.70       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_weights[3] *= 2\n",
    "class_weights[8] *= 2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__class_weight': ['balanced',class_weights],\n",
    "    'classification__class_weight': ['balanced',class_weights],\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6,7,8],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': None, 'classification__min_samples_leaf': 2, 'classification__min_samples_split': 4, 'classification__n_estimators': 99, 'feature_selection__estimator__class_weight': 'balanced', 'feature_selection__n_features_to_select': 9}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.25      0.07      0.11        14\n",
      "           5       0.73      0.79      0.76       185\n",
      "           6       0.70      0.71      0.70       174\n",
      "           7       0.72      0.71      0.72        55\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.71       436\n",
      "   macro avg       0.40      0.38      0.38       436\n",
      "weighted avg       0.69      0.71      0.70       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__class_weight': ['balanced'],\n",
    "    'classification__class_weight': ['balanced'],\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6,7,8],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selection__estimator__class_weight': ['balanced'],\n",
    "    'classification__class_weight': ['balanced'],\n",
    "    'feature_selection__n_features_to_select': [7,8,9,10],\n",
    "    'classification__n_estimators': [98,99,100,101,102],\n",
    "    'classification__max_depth': [None],\n",
    "    'classification__min_samples_split': [4,5,6,7,8],\n",
    "    'classification__min_samples_leaf': [1,2,3,4],\n",
    "    'classification__bootstrap': [True],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
