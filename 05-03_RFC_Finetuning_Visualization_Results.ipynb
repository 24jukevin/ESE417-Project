{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "31680 fits failed out of a total of 126720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15840 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15840 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.64947709 0.64673896 0.64861915]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'pipeline': Pipeline(steps=[('scaling', StandardScaler()),\n",
      "                ('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=0.01, dual=False,\n",
      "                                                     max_iter=5000,\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=42))),\n",
      "                ('classification',\n",
      "                 RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
      "                                        n_estimators=300, random_state=42))]), 'pipeline__classification__bootstrap': True, 'pipeline__classification__max_depth': 20, 'pipeline__classification__min_samples_leaf': 1, 'pipeline__classification__min_samples_split': 2, 'pipeline__classification__n_estimators': 300, 'pipeline__feature_selection__estimator__C': 0.01, 'pipeline__scaling': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('winequality-red.csv', header = 0, delimiter=';')\n",
    "\n",
    "# Preparing the data in in terms of inputs and outputs\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Splitting the data with stratification turned on\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# Define a pipeline setup for the SVC model with linear kernal and l1 regularization\n",
    "pipe1 = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Define a pipeline setup for the RFE using the random forest classifier\n",
    "pipe2 = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', RFE(estimator=RandomForestClassifier(random_state=42))),\n",
    "    ('classification', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Define the grid search containing the two pipelines above\n",
    "param_grid = [\n",
    "    {\n",
    "        'pipeline': [pipe1],\n",
    "        'pipeline__scaling': [MinMaxScaler(), StandardScaler()],\n",
    "        'pipeline__feature_selection__estimator__C': [0.01, 0.1, 1, 10],\n",
    "        'pipeline__classification__n_estimators': [100, 200, 300],\n",
    "        'pipeline__classification__max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        'pipeline__classification__min_samples_split': [1, 2, 5, 10],\n",
    "        'pipeline__classification__min_samples_leaf': [1, 2, 4],\n",
    "        'pipeline__classification__bootstrap': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'pipeline': [pipe2],\n",
    "        'pipeline__scaling': [MinMaxScaler(), StandardScaler()],\n",
    "        'pipeline__feature_selection__n_features_to_select': [5,7,9,11],\n",
    "        'pipeline__classification__n_estimators': [100, 200, 300],\n",
    "        'pipeline__classification__max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        'pipeline__classification__min_samples_split': [1, 2, 5, 10],\n",
    "        'pipeline__classification__min_samples_leaf': [1, 2, 4],\n",
    "        'pipeline__classification__bootstrap': [True, False]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search = GridSearchCV(Pipeline([('pipeline', None)]), param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.74      0.72      0.73       141\n",
      "           6       0.72      0.63      0.67       146\n",
      "           7       0.55      0.69      0.61        32\n",
      "           8       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.39      0.51      0.42       320\n",
      "weighted avg       0.71      0.68      0.69       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5400 fits failed out of a total of 21600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.66513032 0.66513032 0.66513032]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__max_depth': 19, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 3, 'classification__n_estimators': 295, 'feature_selection__estimator__C': 0.01, 'scaling': StandardScaler()}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.74      0.74      0.74       136\n",
      "           6       0.71      0.61      0.66       149\n",
      "           7       0.57      0.68      0.62        34\n",
      "           8       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.39      0.50      0.42       320\n",
      "weighted avg       0.71      0.67      0.69       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Best results had a 69% weighted average. More finetuning around the tested parameters will be performed. Previous cell took 115 mins, 25 seconds to run.\n",
    "\n",
    "# Using only the linearSVC pipeline from above based on gridsearchCV results\n",
    "pipe = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning the RFC parameters, and using only standardscaler for scaling the data\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaling': [StandardScaler()],\n",
    "        'feature_selection__estimator__C': [0.01, 0.1, 1, 10],\n",
    "        'classification__n_estimators': [290, 295, 300, 305, 310],\n",
    "        'classification__max_depth': [None, 10, 15, 17, 18, 19, 20, 21, 22],\n",
    "        'classification__min_samples_split': [1, 2, 3, 4],\n",
    "        'classification__min_samples_leaf': [1, 2, 3],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3920 fits failed out of a total of 15680.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3920 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.67335691 0.6716052  0.67246209]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__max_depth': 17, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 292, 'feature_selection__estimator__C': 0.02, 'scaling': StandardScaler()}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.75      0.73      0.74       139\n",
      "           6       0.73      0.63      0.68       147\n",
      "           7       0.57      0.74      0.65        31\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.40      0.43      0.41       320\n",
      "weighted avg       0.72      0.68      0.70       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Weighted average hasn't gone up, and accuracy has gone down. So has the weighted avg recall. Previous code ran for 13 mins 40 seconds\n",
    "\n",
    "# Using same pipeline from above\n",
    "pipe = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning the RFC parameters\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaling': [StandardScaler()],\n",
    "        'feature_selection__estimator__C': [0.01, 0.02, 0.03, 0.04],\n",
    "        'classification__n_estimators': [290, 291, 292, 293, 294, 295, 296],\n",
    "        'classification__max_depth': [None, 10, 15, 17, 18, 19, 20],\n",
    "        'classification__min_samples_split': [1, 2, 3, 4],\n",
    "        'classification__min_samples_leaf': [1, 2],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "14700 fits failed out of a total of 29400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "14700 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 367, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 758, in _validate_y_class_weight\n",
      "    raise ValueError(\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"balanced subsample\".\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.66259442 0.66259442 0.66770542 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': 17, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 292, 'feature_selection__estimator__C': 0.02, 'scaling': StandardScaler()}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.75      0.73      0.74       139\n",
      "           6       0.73      0.63      0.68       147\n",
      "           7       0.57      0.74      0.65        31\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.40      0.43      0.41       320\n",
      "weighted avg       0.72      0.68      0.70       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Weighted average has improved allong side with accuracy. Precision slightly went up. Slightly tuning parameters more. Previous code ran for 9 minutes 24.3 seconds. Trying out balanced and balanced subsample next\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning the RFC parameters\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaling': [StandardScaler()],\n",
    "        'feature_selection__estimator__C': [0.18, 0.19, 0.02, 0.021, 0.022],\n",
    "        'classification__n_estimators': [290, 291, 292, 293, 294, 295, 296],\n",
    "        'classification__max_depth': [None, 15, 16, 17, 18, 19, 20],\n",
    "        'classification__min_samples_split': [3, 4, 5],\n",
    "        'classification__min_samples_leaf': [1, 2],\n",
    "        'classification__class_weight': ['balanced','balanced subsample'],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.76      0.74      0.75       140\n",
      "           6       0.74      0.64      0.69       149\n",
      "           7       0.53      0.75      0.62        28\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.69       320\n",
      "   macro avg       0.39      0.44      0.41       320\n",
      "weighted avg       0.73      0.69      0.71       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Interestingly enough, when I put C = 0.2 by accident\n",
    "# instead of 0.02, it improved the accuracy.\n",
    "# Will retest the C term, as well as balanced class weights for the feature_selection\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('winequality-red.csv', header = 0, delimiter=';')\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=100000,\n",
    "                                                     dual=False,\n",
    "                                                     penalty='l1', \n",
    "                                                     random_state=42,\n",
    "                                                     C=0.2))),\n",
    "    ('classification', RandomForestClassifier(random_state=42,\n",
    "                                              bootstrap=True,\n",
    "                                              class_weight='balanced',\n",
    "                                              max_depth=17,min_samples_leaf=1,\n",
    "                                              min_samples_split=4,\n",
    "                                              n_estimators=292))\n",
    "]).fit(X_train,y_train)\n",
    "\n",
    "# Making predictions using the fitted RFC model\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': 17, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 292, 'feature_selection__estimator__C': 0.02, 'feature_selection__estimator__class_weight': None, 'scaling': StandardScaler()}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.75      0.73      0.74       139\n",
      "           6       0.73      0.63      0.68       147\n",
      "           7       0.57      0.74      0.65        31\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.40      0.43      0.41       320\n",
      "weighted avg       0.72      0.68      0.70       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning the RFC parameters, checking if setting class weights to balanced on the linearSVC model improves accuracy\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaling': [StandardScaler()],\n",
    "        'feature_selection__estimator__C': [0.02,0.2,0.3],\n",
    "        'feature_selection__estimator__class_weight': ['balanced',None],\n",
    "        'classification__n_estimators': [290, 291, 292, 293, 294, 295, 296],\n",
    "        'classification__max_depth': [None, 15, 16, 17, 18, 19, 20],\n",
    "        'classification__min_samples_split': [3, 4, 5],\n",
    "        'classification__min_samples_leaf': [1, 2],\n",
    "        'classification__class_weight': ['balanced'],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': 17, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 292, 'feature_selection__estimator__C': 0.1, 'feature_selection__estimator__class_weight': None, 'scaling': StandardScaler()}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.76      0.74      0.75       140\n",
      "           6       0.74      0.64      0.69       149\n",
      "           7       0.53      0.75      0.62        28\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.69       320\n",
      "   macro avg       0.39      0.44      0.41       320\n",
      "weighted avg       0.73      0.69      0.71       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Just fine tuning C now. No improvements from setting the class_weight parameter to balanced for linearSVC\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning C for the feature selector \n",
    "param_grid = [\n",
    "    {\n",
    "        'scaling': [StandardScaler()],\n",
    "        'feature_selection__estimator__C': [0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2],\n",
    "        'feature_selection__estimator__class_weight': [None],\n",
    "        'classification__n_estimators': [292],\n",
    "        'classification__max_depth': [17],\n",
    "        'classification__min_samples_split': [4],\n",
    "        'classification__min_samples_leaf': [1],\n",
    "        'classification__class_weight': ['balanced'],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced', 'classification__max_depth': 17, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 292, 'feature_selection__estimator__C': 0.02, 'feature_selection__estimator__class_weight': None, 'scaling': StandardScaler()}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.76      0.73      0.74       142\n",
      "           6       0.72      0.64      0.68       143\n",
      "           7       0.60      0.75      0.67        32\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.69       320\n",
      "   macro avg       0.40      0.44      0.41       320\n",
      "weighted avg       0.72      0.69      0.70       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Just fine tuning C now in linearSVC.\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('scaling', 'passthrough'),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(max_iter=5000, dual=False, penalty='l1', random_state=42))),\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning C for the feature selector at a lower range\n",
    "param_grid = [\n",
    "    {\n",
    "        'scaling': [StandardScaler()],\n",
    "        'feature_selection__estimator__C': [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1],\n",
    "        'feature_selection__estimator__class_weight': [None],\n",
    "        'classification__n_estimators': [292],\n",
    "        'classification__max_depth': [17],\n",
    "        'classification__min_samples_split': [4],\n",
    "        'classification__min_samples_leaf': [1],\n",
    "        'classification__class_weight': ['balanced'],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.76      0.74      0.75       140\n",
      "           6       0.74      0.64      0.69       149\n",
      "           7       0.53      0.75      0.62        28\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.69       320\n",
      "   macro avg       0.39      0.44      0.41       320\n",
      "weighted avg       0.73      0.69      0.71       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Removing the feature selection portion of the pipeline to see if it impacts the model results\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('winequality-red.csv', header = 0, delimiter=';')\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(['quality'], axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('classification', RandomForestClassifier(random_state=42,bootstrap=True,class_weight='balanced',max_depth=17,min_samples_leaf=1,min_samples_split=4,n_estimators=292))\n",
    "]).fit(X_train,y_train)\n",
    "\n",
    "# Make prediction base on X_test\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.76      0.74      0.75       140\n",
      "           6       0.74      0.64      0.69       149\n",
      "           7       0.53      0.75      0.62        28\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.69       320\n",
      "   macro avg       0.39      0.44      0.41       320\n",
      "weighted avg       0.73      0.69      0.71       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Feature selection appears to not impact the RFC model. Removing scaling data to standardized normal distribution to see impact\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('classification', RandomForestClassifier(random_state=42,bootstrap=True,class_weight='balanced',max_depth=17,min_samples_leaf=1,min_samples_split=4,n_estimators=292))\n",
    "]).fit(X_train,y_train)\n",
    "\n",
    "# Make prediction base on X_test\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.76      0.75      0.76       139\n",
      "           6       0.77      0.64      0.70       152\n",
      "           7       0.50      0.74      0.60        27\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.70       320\n",
      "   macro avg       0.39      0.44      0.41       320\n",
      "weighted avg       0.74      0.70      0.71       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Scaling the data appears to not make a difference as well. Re-evaluating class_weight = 'balanced_subsample'\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('classification', RandomForestClassifier(random_state=42,bootstrap=True,class_weight='balanced_subsample',max_depth=17,min_samples_leaf=1,min_samples_split=4,n_estimators=292))\n",
    "]).fit(X_train,y_train)\n",
    "\n",
    "# Make prediction base on X_test\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 8 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "4620 fits failed out of a total of 23100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4620 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.59697689 0.59721954 0.60026453]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classification__bootstrap': True, 'classification__class_weight': 'balanced_subsample', 'classification__max_depth': 15, 'classification__min_samples_leaf': 1, 'classification__min_samples_split': 4, 'classification__n_estimators': 240}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.75      0.73      0.74       140\n",
      "           6       0.72      0.63      0.67       147\n",
      "           7       0.50      0.67      0.57        30\n",
      "           8       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.38      0.42      0.40       320\n",
      "weighted avg       0.71      0.67      0.69       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Testing further gridsearches without feature selection and scaling of data\n",
    "\n",
    "# Defining the pipeline \n",
    "pipe = Pipeline([\n",
    "    ('classification', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Finetuning C for the feature selector \n",
    "param_grid = [\n",
    "    {\n",
    "        'classification__n_estimators': [200,210,220,230,240,250,260,270,280,290,300],\n",
    "        'classification__max_depth': [5,10,15,20,25,30],\n",
    "        'classification__min_samples_split': [1,2,4,8,16],\n",
    "        'classification__min_samples_leaf': [1,2,4,5,6,7,8],\n",
    "        'classification__class_weight': ['balanced_subsample'],\n",
    "        'classification__bootstrap': [True]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Performing the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters from the gridsearch above\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Making predictions based on the gridsearch above\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Printing the classification report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed no further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
